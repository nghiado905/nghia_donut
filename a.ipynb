{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def parse_cord_v2_json(json_path):\n",
    "#     with open(json_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     grouped = defaultdict(lambda: {\"count\": \"\", \"name\": \"\", \"price\": \"\"})\n",
    "\n",
    "#     total_price = \"\"\n",
    "    \n",
    "#     for line in data[\"valid_line\"]:\n",
    "#         category = line[\"category\"]\n",
    "#         group_id = line[\"group_id\"]\n",
    "#         words = \" \".join(w[\"text\"] for w in line[\"words\"])\n",
    "\n",
    "#         if category == \"menu.cnt\":\n",
    "#             grouped[group_id][\"count\"] = words\n",
    "#         elif category in [\"menu.nm\", \"menu.sub_nm\"]:\n",
    "#             grouped[group_id][\"name\"] += words + \" \"\n",
    "#         elif category == \"menu.price\":\n",
    "#             grouped[group_id][\"price\"] = words\n",
    "#         elif category == \"total.total_price\":\n",
    "#             total_price = words\n",
    "\n",
    "#     items = []\n",
    "#     for g in sorted(grouped.keys()):\n",
    "#         entry = grouped[g]\n",
    "#         name = entry[\"name\"].strip()\n",
    "#         if name and entry[\"price\"]:\n",
    "#             items.append({\n",
    "#                 \"name\": name,\n",
    "#                 \"count\": entry[\"count\"],\n",
    "#                 \"price\": entry[\"price\"]\n",
    "#             })\n",
    "\n",
    "#     result = {\n",
    "#         \"items\": items,\n",
    "#         \"total\": total_price\n",
    "#     }\n",
    "\n",
    "#     return result\n",
    "\n",
    "# def prepare_donut_cord_dataset(json_dir, image_dir, output_path):\n",
    "#     dataset = []\n",
    "\n",
    "#     json_files = [f for f in os.listdir(json_dir) if f.endswith(\".json\")]\n",
    "\n",
    "#     for json_file in tqdm(json_files, desc=\"Processing JSON files\"):\n",
    "#         json_path = os.path.join(json_dir, json_file)\n",
    "#         image_name = os.path.splitext(json_file)[0] + \".png\"  # n·∫øu l√† .jpg s·ª≠a ·ªü ƒë√¢y\n",
    "#         image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "#         if not os.path.exists(image_path):\n",
    "#             print(f\"Image not found for {json_file}, skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         text_output = parse_cord_v2_json(json_path)\n",
    "        \n",
    "#         dataset.append({\n",
    "#             \"id\": json_file.replace(\".json\", \"\"),\n",
    "#             \"image_path\": image_path,\n",
    "#             \"text_input\": \"<s_cord-v2>\",  # prefix task\n",
    "#             \"text_output\": json.dumps(text_output, ensure_ascii=False)\n",
    "#         })\n",
    "\n",
    "#     with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(dataset, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "#     print(f\"‚úÖ Done! Saved {len(dataset)} samples to {output_path}\")\n",
    "\n",
    "# # C√°ch ch·∫°y\n",
    "# prepare_donut_cord_dataset(\n",
    "#     json_dir=\"data/json\",\n",
    "#     image_dir=\"data/image\",\n",
    "#     output_path=\"data/train.json\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# image_dir = \"data/images\"\n",
    "# annotation_dir = \"data/annotations\"\n",
    "\n",
    "# # Ki·ªÉm tra th∆∞ m·ª•c t·ªìn t·∫°i\n",
    "# print(\"Th∆∞ m·ª•c images t·ªìn t·∫°i:\", os.path.exists(image_dir))\n",
    "# print(\"Th∆∞ m·ª•c annotation t·ªìn t·∫°i:\", os.path.exists(annotation_dir))\n",
    "\n",
    "# # Li·ªát k√™ c√°c file trong th∆∞ m·ª•c\n",
    "# print(\"File trong images:\", os.listdir(image_dir))\n",
    "# print(\"File trong annotation:\", os.listdir(annotation_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import shutil\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # ƒê·ªãnh nghƒ©a th∆∞ m·ª•c g·ªëc v√† t·ª∑ l·ªá chia d·ªØ li·ªáu\n",
    "# dataset_name = \"cord_dataset\"\n",
    "# image_dir = \"data/images\"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø n·∫øu c·∫ßn\n",
    "# annotation_dir = \"data/annotations\"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø n·∫øu c·∫ßn\n",
    "# train_ratio, val_ratio, test_ratio = 0.8, 0.1, 0.1\n",
    "\n",
    "# # Ki·ªÉm tra th∆∞ m·ª•c\n",
    "# if not os.path.exists(image_dir):\n",
    "#     raise FileNotFoundError(f\"Th∆∞ m·ª•c {image_dir} kh√¥ng t·ªìn t·∫°i\")\n",
    "# if not os.path.exists(annotation_dir):\n",
    "#     raise FileNotFoundError(f\"Th∆∞ m·ª•c {annotation_dir} kh√¥ng t·ªìn t·∫°i\")\n",
    "\n",
    "# # T·∫°o th∆∞ m·ª•c cho dataset\n",
    "# os.makedirs(dataset_name, exist_ok=True)\n",
    "# for split in [\"train\", \"validation\", \"test\"]:\n",
    "#     os.makedirs(os.path.join(dataset_name, split), exist_ok=True)\n",
    "\n",
    "# # H√†m x·ª≠ l√Ω file JSON ƒë·ªÉ t·∫°o ground truth\n",
    "# def process_cord_json(json_path):\n",
    "#     with open(json_path, 'r') as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     menu_items = []\n",
    "#     subtotal = None\n",
    "#     total_info = {}\n",
    "\n",
    "#     grouped_lines = {}\n",
    "#     for line in data[\"valid_line\"]:\n",
    "#         group_id = line[\"group_id\"]\n",
    "#         if group_id not in grouped_lines:\n",
    "#             grouped_lines[group_id] = []\n",
    "#         grouped_lines[group_id].append(line)\n",
    "\n",
    "#     for group_id, lines in grouped_lines.items():\n",
    "#         menu_item = {}\n",
    "#         for line in lines:\n",
    "#             category = line[\"category\"]\n",
    "#             text = \" \".join(word[\"text\"] for word in line[\"words\"])\n",
    "\n",
    "#             if category.startswith(\"menu\"):\n",
    "#                 if category == \"menu.nm\":\n",
    "#                     menu_item[\"name\"] = text\n",
    "#                 elif category == \"menu.cnt\":\n",
    "#                     menu_item[\"count\"] = text\n",
    "#                 elif category == \"menu.price\":\n",
    "#                     menu_item[\"price\"] = text\n",
    "#             elif category == \"sub_total.subtotal_price\":\n",
    "#                 subtotal = text\n",
    "#             elif category.startswith(\"total\"):\n",
    "#                 if category == \"total.total_price\":\n",
    "#                     total_info[\"total_price\"] = text\n",
    "#                 elif category == \"total.cashprice\":\n",
    "#                     total_info[\"cash\"] = text\n",
    "#                 elif category == \"total.changeprice\":\n",
    "#                     total_info[\"change\"] = text\n",
    "#                 elif category == \"total.menutype_cnt\":\n",
    "#                     total_info[\"menu_types\"] = text\n",
    "#                 elif category == \"total.menuqty_cnt\":\n",
    "#                     total_info[\"menu_quantity\"] = text\n",
    "\n",
    "#         if menu_item:\n",
    "#             menu_item.setdefault(\"count\", None)\n",
    "#             menu_item.setdefault(\"price\", None)\n",
    "#             menu_items.append(menu_item)\n",
    "\n",
    "#     ground_truth = {\n",
    "#         \"menu\": menu_items,\n",
    "#         \"subtotal\": subtotal,\n",
    "#         \"total\": total_info\n",
    "#     }\n",
    "#     return ground_truth\n",
    "\n",
    "# # Thu th·∫≠p t·∫•t c·∫£ c√°c file JSON v√† ·∫£nh\n",
    "# data = []\n",
    "# for json_file in os.listdir(annotation_dir):\n",
    "#     if json_file.endswith(\".json\"):\n",
    "#         image_file_base = json_file.replace(\".json\", \"\")\n",
    "#         image_path = None\n",
    "#         for ext in [\".jpg\", \".png\"]:  # H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng ·∫£nh\n",
    "#             temp_path = os.path.join(image_dir, image_file_base + ext)\n",
    "#             if os.path.exists(temp_path):\n",
    "#                 image_path = temp_path\n",
    "#                 image_file = image_file_base + ext\n",
    "#                 break\n",
    "\n",
    "#         if image_path is None:\n",
    "#             print(f\"Kh√¥ng t√¨m th·∫•y ·∫£nh cho {json_file}\")\n",
    "#             continue\n",
    "\n",
    "#         json_path = os.path.join(annotation_dir, json_file)\n",
    "#         ground_truth = process_cord_json(json_path)\n",
    "#         data.append({\n",
    "#             \"image_file\": image_file,\n",
    "#             \"image_path\": image_path,\n",
    "#             \"ground_truth\": ground_truth\n",
    "#         })\n",
    "\n",
    "# # Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu kh√¥ng\n",
    "# if not data:\n",
    "#     raise ValueError(\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu n√†o ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng ki·ªÉm tra th∆∞ m·ª•c images v√† annotation.\")\n",
    "\n",
    "# # Chia d·ªØ li·ªáu th√†nh train, validation, test\n",
    "# train_data, temp_data = train_test_split(data, train_size=train_ratio, random_state=42)\n",
    "# val_data, test_data = train_test_split(temp_data, test_size=test_ratio/(test_ratio + val_ratio), random_state=42)\n",
    "\n",
    "# # H√†m l∆∞u d·ªØ li·ªáu v√†o th∆∞ m·ª•c v√† t·∫°o metadata.jsonl\n",
    "# def save_split(split_data, split_name):\n",
    "#     split_dir = os.path.join(dataset_name, split_name)\n",
    "#     metadata_path = os.path.join(split_dir, \"metadata.jsonl\")\n",
    "\n",
    "#     with open(metadata_path, \"w\") as f:\n",
    "#         for item in split_data:\n",
    "#             dest_image_path = os.path.join(split_dir, item[\"image_file\"])\n",
    "#             shutil.copy(item[\"image_path\"], dest_image_path)\n",
    "\n",
    "#             metadata = {\n",
    "#                 \"file_name\": item[\"image_file\"],\n",
    "#                 \"ground_truth\": json.dumps({\"gt_parse\": item[\"ground_truth\"]})\n",
    "#             }\n",
    "#             f.write(json.dumps(metadata) + \"\\n\")\n",
    "\n",
    "# # L∆∞u d·ªØ li·ªáu v√†o c√°c th∆∞ m·ª•c\n",
    "# save_split(train_data, \"train\")\n",
    "# save_split(val_data, \"validation\")\n",
    "# save_split(test_data, \"test\")\n",
    "\n",
    "# print(\"Dataset ƒë√£ ƒë∆∞·ª£c t·∫°o xong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --dataset_name_or_path dataset --pretrained_model_name_or_path result_new/train_cord/test_experiment --save_path ./result/output.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--task\", type=str, default=\"cord-v2\")\n",
    "# parser.add_argument(\"--pretrained_path\", type=str, default=\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
    "# args, left_argv = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gradio as gr\n",
    "import torch\n",
    "from PIL import Image\n",
    "from donut import DonutModel\n",
    "\n",
    "def demo_process(input_img):\n",
    "    global pretrained_model, task_prompt, task_name\n",
    "    input_img = Image.fromarray(input_img)\n",
    "    output = pretrained_model.inference(image=input_img, prompt=task_prompt)[\"predictions\"][0]\n",
    "    return output\n",
    "\n",
    "def demo_process_vqa(input_img, question):\n",
    "    global pretrained_model, task_prompt, task_name\n",
    "    input_img = Image.fromarray(input_img)\n",
    "    user_prompt = task_prompt.replace(\"{user_input}\", question)\n",
    "    output = pretrained_model.inference(input_img, prompt=user_prompt)[\"predictions\"][0]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'cord'\n",
    "task_prompt = f\"<s_{task_name}>\"\n",
    "\n",
    "pretrained_model = DonutModel.from_pretrained(r\"result_new/train_cord/test_experiment\")\n",
    "# pretrained_model = DonutModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    pretrained_model.half()\n",
    "    device = torch.device(\"cuda\")\n",
    "    pretrained_model.to(device)\n",
    "else:\n",
    "    pretrained_model.encoder.to(torch.bfloat16)\n",
    "\n",
    "# pretrained_model.eval()\n",
    "demo = gr.Interface(\n",
    "    fn=demo_process_vqa if task_name == \"docvqa\" else demo_process,\n",
    "    inputs=[\"image\", \"text\"] if task_name == \"docvqa\" else \"image\",\n",
    "    outputs=\"json\",\n",
    "    title=f\"Donut üç© demonstration for `{task_name}` task\",\n",
    ")\n",
    "demo.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = DonutModel.from_pretrained(\"donut-base-finetuned-docvqa\")\n",
    "\n",
    "def demo_process(input_img):\n",
    "    global pretrained_model, task_prompt, task_name\n",
    "    input_img = Image.fromarray(input_img)\n",
    "    output = pretrained_model.inference(image=input_img, prompt=task_prompt)[\"predictions\"][0]\n",
    "    return output\n",
    "\n",
    "image = cv2.imread(r'D:\\Private\\Project\\kaggle\\LabAI\\Donut\\image.png')\n",
    "demo_process(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from donut import DonutModel\n",
    "\n",
    "# Define the demo_process function (as provided)\n",
    "\n",
    "pretrained_model = DonutModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
    "\n",
    "def demo_process(input_img):\n",
    "    global pretrained_model, task_prompt, task_name\n",
    "    input_img = Image.fromarray(input_img)\n",
    "    output = pretrained_model.inference(image=input_img, prompt=task_prompt)[\"predictions\"][0]\n",
    "    return output\n",
    "\n",
    "# Directory containing images and output\n",
    "image_dir = r'D:\\Private\\Project\\kaggle\\LabAI\\Donut\\donut\\dataset\\train'\n",
    "output_dir = r'D:\\Private\\Project\\kaggle\\LabAI\\Donut\\donut\\dataset\\output'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get all image files in the directory (e.g., .jpg files)\n",
    "image_paths = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
    "\n",
    "# Process each image\n",
    "for image_path in image_paths:\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Check if the image was loaded successfully\n",
    "    if image is None:\n",
    "        print(f\"Could not load image at {image_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the image to get the output\n",
    "    try:\n",
    "        output = demo_process(image_rgb)\n",
    "        # Shorten the output (e.g., first 100 characters)\n",
    "        short_output = str(output)[:100] + ('...' if len(str(output)) > 100 else '')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Create a figure with a larger image and smaller text area\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Display the input image (larger)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Display the shortened output text (smaller area)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.text(0.1, 0.5, short_output, fontsize=10, wrap=True, verticalalignment='center')\n",
    "    plt.title('Output')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Adjust layout to make image dominant\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the combined visualization\n",
    "    output_filename = os.path.join(output_dir, f'result_{os.path.basename(image_path)}')\n",
    "    plt.savefig(output_filename, bbox_inches='tight', dpi=150)\n",
    "    print(f\"Saved result for {image_path} to {output_filename}\")\n",
    "    \n",
    "    # Close the plot to free memory\n",
    "    plt.close()\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm einops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "# from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"5CD-AI/Vintern-1B-v2\"\n",
    "model_name = \"5CD-AI/Vintern-1B-v3_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"5CD-AI/Vintern-1B-v3_5\", revision=\"main\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset 'sroie' doesn't exist on the Hub or cannot be accessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msroie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ki·ªÉm tra xem c√≥ s·∫µn kh√¥ng\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:2062\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2057\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2058\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2059\u001b[0m )\n\u001b[0;32m   2061\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2062\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1782\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1781\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 1782\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1652\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (DataFilesNotFoundError, DatasetNotFoundError, EmptyDatasetError)):\n\u001b[1;32m-> 1652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1578\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[0;32m   1575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevision \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1576\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hub or cannot be accessed.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1579\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1580\u001b[0m     dataset_script_path \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mhf_hub_download(\n\u001b[0;32m   1581\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   1582\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[0;32m   1586\u001b[0m     )\n",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m: Dataset 'sroie' doesn't exist on the Hub or cannot be accessed."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"sroie\")  # Ki·ªÉm tra xem c√≥ s·∫µn kh√¥ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
